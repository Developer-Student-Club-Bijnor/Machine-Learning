# create your classifeir here
ininstall.packages('rpart')
# create your classifeir here
install.packages('rpart')
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
setwd("C:/Users/Prince_K/Downloads/Machine Learning")
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# create your classifeir here
#install.packages('rpart')
library(rpart)
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
y_pred
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier, newdata = test_set[-3],
type = 'class')
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier, newdata = test_set[-3],
type = 'class')
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier, newdata = test_set[-3], type = 'class')
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier, type = 'class', newdata = test_set[-3])
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# create your classifeir here
#install.packages('rpart')
library(rpart)
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier,
type = 'class',
newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
classifier
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier,
newdata = test_set[-3],
type = "class")
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# create your classifeir here
#install.packages('rpart')
library(rpart)
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier,
newdata = test_set[-3],
type = "class")
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
cm
y_pred
0.01 > 0.05
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.05)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.05)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
type = "response",
newdata = grid_set,
type = "class"
)
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.05)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.05)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
newdata = grid_set,
type = "class"
)
y_grid
plot(set[, 3],
main = "Decision Tree Classifiaction (Training Set)",
xlab = "Age", ylab="Estimated Salary",
xlim=range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch='.', col=ifelse(y_grid ==1, 'springgreen3', 'tomato') )
points(set, pch=21, bg=ifelse(set[, 3] ==1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.05)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.05)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
newdata = grid_set,
type = "class"
)
plot(set[, 3],
main = "Decision Tree Classifiaction (Training Set)",
xlab = "Age", ylab="Estimated Salary",
xlim=range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch='.', col=ifelse(y_grid ==1, 'springgreen3', 'tomato') )
points(set, pch=21, bg=ifelse(set[, 3] ==1, 'green4', 'red3'))
cm
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# create your classifeir here
#install.packages('rpart')
library(rpart)
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier,
newdata = test_set[-3],
type = "class")
# Ploting Decision Tree without Feature Scaling
plot(classifier)
text(classifier)
# Ploting Decision Tree without Feature Scaling
plot(classifier)
text(classifier)
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
### ============ Important =============== ###
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0,1))
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# create your Random Forest Classification here
#install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-3],
y = training_set$Purchased,
ntree = 10)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
cm
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
### ============ Important =============== ###
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0,1))
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, -3] = scale(training_set[, -3])
test_set[, -3] = scale(test_set[, -3])
# create your Random Forest Classification here
#install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-3],
y = training_set$Purchased,
ntree = 10)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
cm
y_pred
classifier = randomForest(x = training_set[-3],
y = training_set$Purchased,
ntree = 500)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
cm
classifier = randomForest(x = training_set[-3],
y = training_set$Purchased,
ntree = 10)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
# Visualise the training set results
#install.packages('ElemStatLearn')
library(ElemStatLearn)
cm
set = training_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.01)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
type = "response",
newdata = grid_set
)
plot(set[, 3],
main = "Random Forest Classification(Training Set)",
xlab = "Age", ylab="Estimated Salary",
xlim=range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch='.', col=ifelse(y_grid ==1, 'springgreen3', 'tomato') )
points(set, pch=21, bg=ifelse(set[, 3] ==1, 'green4', 'red3'))
set = test_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.01)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
type = "response",
newdata = grid_set
)
plot(set[, 3],
main = " Random Forest Classification (Test Set)",
xlab = "Age", ylab="Estimated Salary",
xlim=range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch='.', col=ifelse(y_grid ==1, 'springgreen3', 'tomato') )
points(set, pch=21, bg=ifelse(set[, 3] ==1, 'green4', 'red3'))
setwd("C:/Users/Prince_K/Downloads/Machine Learning/Part 4 - Clustering")
# Importing the mall dataset
dataset <- read.csv('Mall_Customers.csv')
# Importing the mall dataset
dataset <- read.csv('Mall_Customers.csv')
View(dataset)
X <- dataset[4:5]
View(X)
# using the elbow method to find no of clusters
set.seed(6)
wcss <- vector()
for(i in 1:10) wcss[i] <- sum(kmeans(X, i)$withinss)
plot(1:10, wcss, type='b', main = paste("Clusters of clients"),
xlab = "Number of clusters", ylab = "WCSS")
# Applying k-means to mall dataset
set.seed(29)
kmeans <- kmeans(X, 5, iter.max = 300, nstart = 10)
# Visualizing the clusters
library(cluster)
clusplot(X,
kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of Clients'),
xlab = "Annual Income",
ylab = "Spanding Score")
clusplot(X,
kmeans$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of Clients'),
xlab = "Annual Income",
ylab = "Spanding Score")
source('C:/Users/Prince_K/Downloads/Machine Learning/Part 4 - Clustering/K-means Clustering.R')
# Importing the mall dataset
dataset <- read.csv('Mall_Customers.csv')
X <- dataset[4:5]
View(dataset)
View(X)
# Using dendrogram to find optimal no of clusters
dendrogram = hclust(dist(x, method = 'euclidean'),
method = 'ward.D',
)
plot(dendrogram, main = paste("Dendrogram"),
xlab= 'Customers',
ylab = "Euclidean Distance")
# Using dendrogram to find optimal no of clusters
dendrogram = hclust(dist(X, method = 'euclidean'),
method = 'ward.D',
)
plot(dendrogram, main = paste("Dendrogram"),
xlab= 'Customers',
ylab = "Euclidean Distance")
# Fitting hierarchical cluster to the mall dataset
hc = hclust(dist(X, method = 'euclidean'), method = 'ward.D')
y_hc = cutree(hc, k=5)
View(hc)
y_hc
# Visualizing the clusters
library(cluster)
clusplot(X,
y_hc,
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of Clients'),
xlab = "Annual Income",
ylab = "Spanding Score")
# Importing the dataset
dataset = read.csv('Mall_Customers.csv')
dataset = dataset[4:5]
# Using the dendrogram to find the optimal number of clusters
dendrogram = hclust(d = dist(dataset, method = 'euclidean'), method = 'ward.D')
plot(dendrogram,
main = paste('Dendrogram'),
xlab = 'Customers',
ylab = 'Euclidean distances')
# Fitting Hierarchical Clustering to the dataset
hc = hclust(d = dist(dataset, method = 'euclidean'), method = 'ward.D')
y_hc = cutree(hc, 5)
# Visualising the clusters
library(cluster)
clusplot(dataset,
y_hc,
lines = 0,
shade = TRUE,
color = TRUE,
labels= 2,
plotchar = FALSE,
span = TRUE,
main = paste('Clusters of customers'),
xlab = 'Annual Income',
ylab = 'Spending Score')
