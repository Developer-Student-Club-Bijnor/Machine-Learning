# create your classifeir here
ininstall.packages('rpart')
# create your classifeir here
install.packages('rpart')
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
setwd("C:/Users/Prince_K/Downloads/Machine Learning")
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# create your classifeir here
#install.packages('rpart')
library(rpart)
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
y_pred
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier, newdata = test_set[-3],
type = 'class')
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier, newdata = test_set[-3],
type = 'class')
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier, newdata = test_set[-3], type = 'class')
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier, type = 'class', newdata = test_set[-3])
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# create your classifeir here
#install.packages('rpart')
library(rpart)
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier,
type = 'class',
newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
classifier
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier,
newdata = test_set[-3],
type = "class")
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# create your classifeir here
#install.packages('rpart')
library(rpart)
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier,
newdata = test_set[-3],
type = "class")
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
cm
y_pred
0.01 > 0.05
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.05)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.05)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
type = "response",
newdata = grid_set,
type = "class"
)
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.05)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.05)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
newdata = grid_set,
type = "class"
)
y_grid
plot(set[, 3],
main = "Decision Tree Classifiaction (Training Set)",
xlab = "Age", ylab="Estimated Salary",
xlim=range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch='.', col=ifelse(y_grid ==1, 'springgreen3', 'tomato') )
points(set, pch=21, bg=ifelse(set[, 3] ==1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.05)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.05)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
newdata = grid_set,
type = "class"
)
plot(set[, 3],
main = "Decision Tree Classifiaction (Training Set)",
xlab = "Age", ylab="Estimated Salary",
xlim=range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch='.', col=ifelse(y_grid ==1, 'springgreen3', 'tomato') )
points(set, pch=21, bg=ifelse(set[, 3] ==1, 'green4', 'red3'))
cm
# Decision Tree Classifiaction
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# create your classifeir here
#install.packages('rpart')
library(rpart)
classifier = rpart(formula = Purchased ~ .,
data = training_set)
# Predicting the test set
#y_pred = predict(classifier, newdata = test_set[-3])
y_pred = predict(classifier,
newdata = test_set[-3],
type = "class")
# Ploting Decision Tree without Feature Scaling
plot(classifier)
text(classifier)
# Ploting Decision Tree without Feature Scaling
plot(classifier)
text(classifier)
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
### ============ Important =============== ###
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0,1))
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] = scale(training_set[, 1:2])
test_set[, 1:2] = scale(test_set[, 1:2])
# create your Random Forest Classification here
#install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-3],
y = training_set$Purchased,
ntree = 10)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
cm
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[, 3:5]
### ============ Important =============== ###
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0,1))
# Splitting dataset into training set and test set
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling
training_set[, -3] = scale(training_set[, -3])
test_set[, -3] = scale(test_set[, -3])
# create your Random Forest Classification here
#install.packages('randomForest')
library(randomForest)
classifier = randomForest(x = training_set[-3],
y = training_set$Purchased,
ntree = 10)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
cm
y_pred
classifier = randomForest(x = training_set[-3],
y = training_set$Purchased,
ntree = 500)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
cm
classifier = randomForest(x = training_set[-3],
y = training_set$Purchased,
ntree = 10)
# Predicting the test set
y_pred = predict(classifier, newdata = test_set[-3])
# Making the confusion matrix
cm = table(test_set[, 3], y_pred)
# Visualise the training set results
#install.packages('ElemStatLearn')
library(ElemStatLearn)
cm
set = training_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.01)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
type = "response",
newdata = grid_set
)
plot(set[, 3],
main = "Random Forest Classification(Training Set)",
xlab = "Age", ylab="Estimated Salary",
xlim=range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch='.', col=ifelse(y_grid ==1, 'springgreen3', 'tomato') )
points(set, pch=21, bg=ifelse(set[, 3] ==1, 'green4', 'red3'))
set = test_set
X1 = seq(min(set[, 1] -1), max(set[, 1] + 1), by=0.01)
X2 = seq(min(set[, 2] -1), max(set[, 2] + 1), by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,
type = "response",
newdata = grid_set
)
plot(set[, 3],
main = " Random Forest Classification (Test Set)",
xlab = "Age", ylab="Estimated Salary",
xlim=range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch='.', col=ifelse(y_grid ==1, 'springgreen3', 'tomato') )
points(set, pch=21, bg=ifelse(set[, 3] ==1, 'green4', 'red3'))
setwd("C:/Users/Prince_K/Downloads/Machine Learning/Part 5 - Association Rule Learning")
dataset = read.csv('Market_BAsket_Optimisation.csv',
header = FALSE)
# install.packages('arules')
library(Matrix)
library(arules)
dataset = read.transactions('Market_BAsket_Optimisation.csv',
sep =',',
rm.duplicates = TRUE)
summary(dataset)
itemFrequencyPlot(dataset, topN = 10)
itemFrequencyPlot(dataset, topN = 100)
# Training Eclat on the dataset
# support = 3*7 /7500
rules = eclat(data = dataset,
parameter = list(support = 0.004, min_len=2))
# Training Eclat on the dataset
# support = 3*7 /7500
rules = eclat(data = dataset,
parameter = list(support = 0.004, minlen=2))
# Visualising the results
inspect(sort(rules, by = 'support')[1:10])
