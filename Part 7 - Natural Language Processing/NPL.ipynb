{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                Review  Liked\n0                             Wow... Loved this place.      1\n1                                   Crust is not good.      0\n2            Not tasty and the texture was just nasty.      0\n3    Stopped by during the late May bank holiday of...      1\n4    The selection on the menu was great and so wer...      1\n..                                                 ...    ...\n995  I think food should have flavor and texture an...      0\n996                           Appetite instantly gone.      0\n997  Overall I was not impressed and would not go b...      0\n998  The whole experience was underwhelming, and I ...      0\n999  Then, as if I hadn't wasted enough of my life ...      0\n\n[1000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n      <th>Liked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Wow... Loved this place.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Crust is not good.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Not tasty and the texture was just nasty.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Stopped by during the late May bank holiday of...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>The selection on the menu was great and so wer...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>995</td>\n      <td>I think food should have flavor and texture an...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>996</td>\n      <td>Appetite instantly gone.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>997</td>\n      <td>Overall I was not impressed and would not go b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>998</td>\n      <td>The whole experience was underwhelming, and I ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>999</td>\n      <td>Then, as if I hadn't wasted enough of my life ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter='\\t', quoting=3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to /home/its-k/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')  # Remove non-relevent words like- a,an,the,....\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer  # apply stemming\n",
    "# stemming means finding the root word of words -\n",
    "# words -----> root word\n",
    "# loved, loving, lovely, love -----> love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = []     # cleaned reviews\n",
    "for i in range(0, len(dataset)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])     # replace punctuation by space\n",
    "    review = review.lower().split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    for w in [\"no\", \"not\", \"don't\", \"aren't\", \"couldn't\", \"won't\", \"shouldn't\", \"wouldn't\"]:\n",
    "        all_stopwords.remove(w)\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['wow love place',\n 'crust not good',\n 'not tasti textur nasti',\n 'stop late may bank holiday rick steve recommend love',\n 'select menu great price',\n 'get angri want damn pho',\n 'honeslti tast fresh',\n 'potato like rubber could tell made ahead time kept warmer',\n 'fri great',\n 'great touch']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Bag of Words model(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1000, 1567)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.fit_transform(corpus).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1540)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Naive Bayes to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianNB(priors=None, var_smoothing=1e-09)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0 1]\n [0 1]\n [0 1]\n [0 0]\n [0 0]\n [0 1]\n [1 1]\n [0 1]\n [0 1]\n [1 1]\n [1 1]\n [1 1]\n [0 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [1 0]\n [1 1]\n [0 1]\n [0 1]\n [1 0]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [0 0]\n [0 1]\n [1 1]\n [1 1]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [0 0]\n [0 1]\n [0 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [1 1]\n [0 1]\n [0 0]\n [0 1]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [1 1]\n [1 0]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [0 1]\n [0 0]\n [1 1]\n [0 1]\n [0 0]\n [1 1]\n [0 0]\n [0 0]\n [0 1]\n [1 1]\n [0 1]\n [1 1]\n [1 1]\n [0 1]\n [1 0]\n [1 1]\n [1 1]\n [0 1]\n [1 0]\n [0 1]\n [1 1]\n [1 1]\n [0 0]\n [1 0]\n [1 0]\n [1 1]\n [0 0]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 0]\n [1 1]\n [0 1]\n [0 0]\n [0 0]\n [1 1]\n [0 1]\n [0 0]\n [1 1]\n [0 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [0 1]\n [1 0]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [0 0]\n [0 1]\n [1 1]\n [1 1]\n [1 1]\n [1 1]\n [1 0]\n [1 1]\n [1 1]\n [0 1]\n [0 0]\n [1 1]\n [1 1]\n [1 1]\n [0 1]\n [0 1]\n [0 0]\n [1 0]\n [1 1]\n [0 0]\n [0 0]\n [0 1]\n [0 0]\n [0 0]\n [1 0]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [0 0]\n [1 0]\n [1 1]\n [0 0]\n [0 0]\n [0 1]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [0 0]\n [0 1]\n [0 1]\n [1 1]\n [0 0]\n [1 1]\n [1 1]\n [0 1]\n [1 1]]\n"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_test.reshape(-1, 1), y_pred.reshape(-1, 1)), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[55, 42],\n       [12, 91]])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.73"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6842105263157895"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.883495145631068"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7711864406779663"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting if a single review is positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our model to predict if the following review is positive or negative:\n",
    "\n",
    "\" I love this restaurant so much\"\n",
    "\n",
    "\n",
    "**Solution**: We just repeat the same text preprocessing process we did before with single review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1])"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "new_review = \"I love this restaurant so much\"\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower().split()\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = \" \".join(new_review)\n",
    "new_X = cv.transform([new_review]).toarray()\n",
    "classifier.predict(new_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review was correctly predicted as positive by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our model to predict if the following review is positive or negative:\n",
    "\n",
    "\" I hate this resturant so much.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "new_review = \" I hate this resturant so much.\"\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower().split()\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = \" \".join(new_review)\n",
    "new_X = cv.transform([new_review]).toarray()\n",
    "classifier.predict(new_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review was correctly predicted as negative by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}